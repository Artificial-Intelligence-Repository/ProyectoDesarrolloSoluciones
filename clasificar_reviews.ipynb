{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BnV8XyBDosG"
      },
      "source": [
        "Importación de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6xHqlr-TDosI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.datasets import load_files\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import scipy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Linear regression\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeidsPo3DosK"
      },
      "source": [
        "Cambiar el workdir si se ejecuta el notebook localmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9J4G19H_DosK"
      },
      "outputs": [],
      "source": [
        "# os.chdir(r\"C:\\Users\\aeveg\\OneDrive\\Documentos\\MASTERS\\Proyecto\\Proyecto de Materia\\ProyectoDesarrolloSoluciones\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmbyMZKVDosK"
      },
      "source": [
        "# Procesando los archivos del conjunto de datos\n",
        "\n",
        "El conjunto de datos de reseñas de IMDB se encuentra constituido por una carpeta data que contiene dos carpetas, train y test, cada una con dos carpetas, pos y neg, que contienen 12500 archivos de texto con las reseñas de IMDB. Es necesario unificar estos archivos en un solo archivo CSV llamado imdb_reviews_train.csv y imdb_reviews_test.csv, respectivamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3k4ZZAIpDosL",
        "outputId": "b28f9d19-53b6-4eed-a889-28e99616a7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verificando estructura de data de entrenamiento\n",
            "                                              review  sentiment\n",
            "0  In Panic In The Streets Richard Widmark plays ...          1\n",
            "1  If you ask me the first one was really better ...          0\n",
            "2  I am a big fan a Faerie Tale Theatre and I've ...          1\n",
            "3  I just finished reading a book about Dillinger...          0\n",
            "4  Greg Davis and Bryan Daly take some crazed sta...          0\n",
            "                                                  review  sentiment\n",
            "24995  My roommates & I nearly shorted out our TV fro...          0\n",
            "24996  Michelle Rodriguez is the defining actress who...          1\n",
            "24997  Nice movie with a great soundtrack which spans...          1\n",
            "24998  Even though this was a made-for-TV production,...          0\n",
            "24999  I saw this on cable recently and kinda enjoyed...          0\n",
            "Total de reseñas de entrenamiento: 25000\n",
            "Verificando estructura de data de prueba\n",
            "                                              review  sentiment\n",
            "0  When I was a kid, I loved \"Tiny Toons\". I espe...          1\n",
            "1  The setup for \"Nature of the Beast\" is ingenio...          0\n",
            "2  I do not have much to say than this is a great...          1\n",
            "3  Extremely formulaic with cosmic-sized logic ho...          0\n",
            "4  I actually liked certain things about this gam...          0\n",
            "                                                  review  sentiment\n",
            "24995  Start with the premise that you will do anythi...          0\n",
            "24996  This movie gives us some WWII history along wi...          1\n",
            "24997  In my opinion this is the best Oliver Stone fl...          1\n",
            "24998  It's certainly a direct-to-video, but the stor...          0\n",
            "24999  This movie was obscenely obvious and predictab...          0\n",
            "Total de reseñas de prueba: 25000\n"
          ]
        }
      ],
      "source": [
        "def leer_archivos_en_directorio(directorio, sentimiento):\n",
        "    \"\"\"\n",
        "    Lee todos los archivos de texto en 'directorio' y devuelve una lista de diccionarios,\n",
        "    cada uno con el texto, el sentimiento (pos/neg) y si es train o test.\n",
        "    \"\"\"\n",
        "    registros = []\n",
        "    for filename in os.listdir(directorio):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            ruta_archivo = os.path.join(directorio, filename)\n",
        "            with open(ruta_archivo, \"r\", encoding=\"utf-8\") as f:\n",
        "                texto = f.read()\n",
        "            registros.append({\n",
        "                \"review\": texto,\n",
        "                \"sentiment\": sentimiento,  # 1 = positivo, 0 = negativo\n",
        "                #\"split\": tipo              # 'train' o 'test'\n",
        "            })\n",
        "    return registros\n",
        "\n",
        "# Rutas (ajusta según tu sistema)\n",
        "ruta_train_pos = \"data/train/pos\"\n",
        "ruta_train_neg = \"data/train/neg\"\n",
        "ruta_test_pos  = \"data/test/pos\"\n",
        "ruta_test_neg  = \"data/test/neg\"\n",
        "\n",
        "# Leemos los archivos de cada carpeta\n",
        "train_pos = leer_archivos_en_directorio(ruta_train_pos, sentimiento=1)\n",
        "train_neg = leer_archivos_en_directorio(ruta_train_neg, sentimiento=0)\n",
        "test_pos  = leer_archivos_en_directorio(ruta_test_pos,  sentimiento=1)\n",
        "test_neg  = leer_archivos_en_directorio(ruta_test_neg,  sentimiento=0)\n",
        "\n",
        "# Convertimos las listas de datos de train y test a un DataFrame de pandas\n",
        "train_df = pd.DataFrame(train_pos + train_neg)\n",
        "test_df = pd.DataFrame(test_pos + test_neg)\n",
        "\n",
        "# Desordenamos aleatoriamente los DataFrames\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Verificamos un poco la estructura de la data de entrenamiento\n",
        "print(\"Verificando estructura de data de entrenamiento\")\n",
        "print(train_df.head())\n",
        "print(train_df.tail())\n",
        "print(\"Total de reseñas de entrenamiento:\", len(train_df))\n",
        "\n",
        "# Exportamos a CSV (sin índice)\n",
        "train_df.to_csv(\"data/imdb_reviews_train.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Verificamos un poco la estructura de la data de prueba\n",
        "print(\"Verificando estructura de data de prueba\")\n",
        "print(test_df.head())\n",
        "print(test_df.tail())\n",
        "print(\"Total de reseñas de prueba:\", len(test_df))\n",
        "\n",
        "# Exportamos a CSV (sin índice)\n",
        "test_df.to_csv(\"data/imdb_reviews_test.csv\", index=False, encoding=\"utf-8\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMQftzekDosL"
      },
      "source": [
        "Obteniendo data de entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeewjQPRDosL"
      },
      "outputs": [],
      "source": [
        "def load_imdb_reviews(ruta_archivo):\n",
        "    # Lee el archivo CSV y lo guarda en un DataFrame\n",
        "    df = pd.read_csv(ruta_archivo)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "zD6CcVr4DosL",
        "outputId": "61f0cc3d-a1e0-49d1-9c9a-671c719a00f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeras 5 filas del conjunto de datos de entrenamiento de reseñas de IMDB en en español:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In Panic In The Streets Richard Widmark plays ...          1\n",
              "1  If you ask me the first one was really better ...          0\n",
              "2  I am a big fan a Faerie Tale Theatre and I've ...          1\n",
              "3  I just finished reading a book about Dillinger...          0\n",
              "4  Greg Davis and Bryan Daly take some crazed sta...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21e7c779-7c10-4fe2-8b74-f38e9a4a69fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you ask me the first one was really better ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I just finished reading a book about Dillinger...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21e7c779-7c10-4fe2-8b74-f38e9a4a69fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21e7c779-7c10-4fe2-8b74-f38e9a4a69fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21e7c779-7c10-4fe2-8b74-f38e9a4a69fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b7bba76-e587-444f-a443-3e22b01a3392\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b7bba76-e587-444f-a443-3e22b01a3392')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b7bba76-e587-444f-a443-3e22b01a3392 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24904,\n        \"samples\": [\n          \"The only reason I wanted to see this was because of Orlando Bloom. Simply put, the movie was spectacularly average. It's not bad, but it's really not very good. The editing is good; the film is well-paced. The direction is competent and assured. The story is plodding. The film is averagely acted by Ledger, Bloom, and the normally great Watts and Rush. The accents are impenetrable if you're from the US so just sit back and enjoy the scenery (or as I like to call it, Orlando Bloom). By the end of the film, I was neither bored nor moved. Some people have asked what happened to Ned Kelly at the end of the movie. I have to say, I so did not care by that point.<br /><br />Really, the only reason I can recommend this is that Orlando Bloom kind of, sort of shows some hints of range (although the oft-present \\\"I'm pretty and confused\\\" look is prominent), so fangirls may find it worth the matinee price. Other than that, just don't see it. It's neither good enough nor bad enough to be entertaining.\",\n          \"I cannot believe that I wasted five hours of my life on this rubbish. The previous five day offering by this author was highly enjoyable and I was really looking forward to this. But most of the dialogue was completely incomprehensible. Suranne Jones was the principal culprit since she either mumbled or gabbled her lines, but most of the rest of the cast followed her example. Notable exceptions were Bernard Hill and Anne Reid, old stagers whose diction was exemplary. Do producers not listen to productions before they are aired to make sure the dialogue is audible? As a result I suppose I lost track of what was going on, and since the original plot line seemed to metamorphose into to the standard them-and-us thing between Muslims and the rest I soon lost interest. The ending was a complete anti-climax. A complete dud.\",\n          \"An excellent film depicting the cross currents in the lives of a multi-ethnic mix of not so ordinary people in the rural Pacific Northwest. Solid directing and writing along with fine acting, especially the performances by Kwami Taha and Dan Stowe. Interestingly, this film was made in the same year as the highly successful \\\"Crash,\\\" written and directed by Paul Haggis. The pace of the action may not be as frantic as that in urban Los Angeles, and the characters may seem to be better acquainted with each other in \\\"Apart From That,\\\" but the personal relationships of the characters are as flawed and troubled and their stories as resonant as any of those in \\\"Crash.\\\" For those viewers who appreciated \\\"Crash\\\" this is a must see film. Also, fans of Jim Jarmusch and John Cassavetes will like this movie.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#df_train = load_imdb_reviews('./data/imdb_reviews_train_espanol.csv')\n",
        "df_train = load_imdb_reviews('./data/imdb_reviews_train.csv')\n",
        "print(\"\\nPrimeras 5 filas del conjunto de datos de entrenamiento de reseñas de IMDB en en español:\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Pgl9GzT-DosM",
        "outputId": "63ae019e-3343-409c-c692-ab29b8bc2347"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "0    12500\n",
              "1    12500\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df_train.groupby('sentiment').size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXSVVGLgDosM"
      },
      "source": [
        "Imprimiendo 5 ejemplos de la clase negativa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yneZNDHDDosM",
        "outputId": "be21a513-32c3-4d12-a044-7a788376da25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['If you ask me the first one was really better one. Look at Sarah M. G., she is real, mean, cruel girl, look at Amy Adams she is just little fool hanging around. She is nothing! People don\\'t adore her! Second, Sebastian was cute and hot in first movie, now he is \"baby face\". Story is not that good, and i do not understand. Why didn\\'t they make this one first, it is the beginning. Loosy actors, nothing with story. This is not cruel, this is playing. First one has better actors, better story, and its mean. I think that the music is better in cruel intentions 1 and the music is better in cruel intentions 3. It is not the worst movie I saw, but in compaer with first one its one big, big, big nothing.'\n",
            " 0]\n",
            "[\"I just finished reading a book about Dillinger. This movie was horribly inaccurate. It's like they got a list of names and just made everything up. His robberies and getaways were well planned, down to the second - when the time was up, they left whether they had all of the money or not. They had notes of every road, where to turn, etc. Purvis never saw him at the restaurant, he was told that Dillinger paid for his meal after Dillinger left. Purvis never even SAW Dillinger before the night Dillinger was killed, only photos of him. The way his gang members died were fictitious. Dillinger never robbed a bank by himself, like he did in this movie. If I had never read the book, maybe I could have enjoyed the movie. The acting was a bit over the top in places. The action was overdone as well. On second thought, I doubt if I would have enjoyed it much even if I HADN'T read the book.\"\n",
            " 0]\n",
            "['Greg Davis and Bryan Daly take some crazed statements by a terrorists, add some commentary by a bunch of uber-right reactionaries, ascribe the most extreme positions of the most fundamentalist Moslems on the planet to everyone who calls themselves a Moslem, and presents this as the theology of Islam. Maybe their next film will involve interviewing Fred Phelps and the congregation of the Westboro Baptist Church, adding commentary by some militant atheist \"scholars, and call their film \"What the World Needs to Know About Christianity.\" Ultimately, this film suffers from both poor production values and lack of attention to the most basic standards of journalism. Don\\'t waste your time and money; just turn on your AM radio and listen to Rush Limbaugh for a couple of days for free and you\\'ll get the same message with the same level of intellectual analysis.'\n",
            " 0]\n",
            "['As a writer I find films this bad making it into production a complete slap in the face. Talk about insulting. I was writing better stories than this in 8th grade. Bad acting, bad writing, bad directing and when added all together the result is complete and total failure. <br /><br />The only thing this movie manages to accomplish is tricking the unsuspecting consumer into wasting their time. Who would green light something so poorly written? It\\'s not artistic, clever, smart, suspenseful, mysterious, scary, dramatic-NOTHING.<br /><br />The characters are flat and boring with no development. The plot is as recycled as an aluminum can. They somehow managed to cast a few very familiar actors who all must be pretty desperate for work or hoping one of these low budget independent movies will turn out to be the next \"Pulp Fiction\". This script should have been used to line a bird cage, not a movie. <br /><br />Oh and last but not least, a 5\\'2 105 lb woman of course has the strength to kill men and women twice her size without a struggle and in a single blow. <br /><br />Avoid this bomb like it will infect you with an STD.'\n",
            " 0]\n",
            "[\"Not one of Keaton's best efforts, this was perhaps a veiled attempt to revenge himself on the family he married into - the Talmadges. A Polish/English language barrier and a series of coincidences leads Buster into a marriage with a large Irish woman, who (along with her father and brothers) treat him shabbily until they think he may be an heir to a fortune. Mistaken identities abound here - gags are set up and but for the main fail to pay off.<br /><br />This Metro short does have at least two real laughs - Buster's cleverly turning around his lack of dinner by using the calendar on the wall and the basic ignorance of his adopted family to literally bring the meat to his plate. The other is a family photo, with the entire group slowly collapsing to the floor as the tripod of the camera loses its stability.<br /><br />The yeast beer overflow could have been the catalyst for a massive series of gags built upon gags, but stops short (for all the buildup) of development.<br /><br />Kino's print is crisp and clear and the score is one for player piano, drums and sound effects. Not one of Buster's best efforts, but worth a few laughs.\"\n",
            " 0]\n"
          ]
        }
      ],
      "source": [
        "for review in np.array(df_train)[np.array(df_train.sentiment) == 0][:5]:\n",
        "    print(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clfNCbi2DosN"
      },
      "source": [
        "Imprimiendo 5 ejemplos de la clase positiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi5Qr6ldDosN",
        "outputId": "887f2897-b4d9-40c7-fd32-bb5f73bf495f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"In Panic In The Streets Richard Widmark plays U.S. Navy doctor who has his week rudely interrupted with a corpse that contains plague. As cop Paul Douglas properly points out the guy died from two bullets in the chest. That's not the issue here, the two of them become unwilling partners in an effort to find the killers and anyone else exposed to the disease.<br /><br />As was pointed out by any number of people, for some reason director Elia Kazan did not bother to cast the small parts with anyone that sounds like they're from Louisiana. Having been to New Orleans where the story takes place I can personally attest to that. Richard Widmark and his wife Barbara Bel Geddes can be excused because as a Navy doctor he could be assigned there, but for those that are natives it doesn't work.<br /><br />But with plague out there and the news being kept a secret, the New Orleans PD starts a dragnet of the city's underworld. The dead guy came off a ship from Europe and he had underworld connections. A New Orleans wise guy played by Jack Palance jumps to a whole bunch of erroneous conclusions and starts harassing a cousin of the dead guy who is starting to show plague symptoms. Palance got rave reviews in the first film where he received notice.<br /><br />Personally my favorite in this film is Zero Mostel. This happened right before Mostel was blacklisted and around that time he made a specialty of playing would be tough guys who are really toadies. He plays the same kind of role in the Humphrey Bogart film, The Enforcer. Sadly I can kind of identify with Mostel in that last chase scene where he and Palance are being chased down by Widmark, Douglas, and half the New Orleans Police. Seeing the weight challenged Zero trying to keep up with Palance was something else because I'm kind of in Zero's league now in the heft department.<br /><br />Kazan kept the action going at a good clip, there's very little down time in this film. If there was any less it would be an Indiana Jones film. Panic In The Streets won an Oscar for Best Original Screenplay that year.<br /><br />Kazan also made good use of the New Orleans waterfront and the French Quarter. Some of the same kinds of shots are later used in On the Waterfront. In fact Panic In The Streets is about people not squealing when they really should in their own best interest. Very similar again to On the Waterfront.<br /><br />Panic In The Streets does everyone proud who was associated with it. Now why couldn't Elia Kazan get some decent New Orleans sounding people in the small roles.\"\n",
            " 1]\n",
            "[\"I am a big fan a Faerie Tale Theatre and I've seen them all and this is one of the best! It's funny, romantic, and a classic. I recommend this for all ages. It's great for little kids because it's well, Cinderella and great for adults and teen because it's funny and not over the top. I watched it when I was little and I still watch it now. It has great lines that my family and I quote all the time. The acting is great and it never gets old. If you like fairy tales and romances you will love this. I've watched many a Cinderella movie in my time and this is the best of them all. (Sorry Disney) I highly recommend this movie and all the Faerie Tale Theatre shows. They all appeal to all ages and are all unique and very entertaining.\"\n",
            " 1]\n",
            "[\"This really is an incredible film. Not only does it document the eternal struggle of indigenous and disenfranchised people to gain their rightful voice but it also shows the United States up for its dishonesty, subterfuge, and blatant disregard for human rights and self-determination. Chavez is shown as a very brave and charismatic leader struggling against what can only be characterized as a despicable elite devoid of any sense of proportion or justice. These filmmakers have recorded a coup unlike anything witnessed before.<br /><br />And in the cross hairs we see the USA, once again pulling the strings and blurring all sense of reality. It's heart-breaking to watch the initial stages of the revolt knowing full well that the subversion of democracy that we're witnessing is a tool long used by successive American governments and their seemingly blinkered citizens. The footage makes it clear that this is not a manipulation of TV or generic footage but an active documentation of a people and its government fighting for its future. Truly a moving experience for anyone with a conscience. These Irish film makers deserve our gratitude. Long live Chavez.<br /><br />We need to enshrine the notion that each country must be allowed to choose its government and to develop in ways that the majority sees fit. First phase in this process is the need to know what the realities of the situation are, and this documentary does a great job of doing just that.\"\n",
            " 1]\n",
            "['If you lived through the 60s, this film can be at times painful and other times quite joyous. It\\'s all there but the small print in the counter culture tabloids prevalent at the time. These are the roots of a social revolution that is still playing out: \"don\\'t speak too soon for the wheel\\'s still in spin, for the times they are a-changin\\'\". While the film focuses on the revolutionary nature of LSD and it\\'s dissemination at the time, that alone played a tremendous hand in the evolution of the intelligentsia, influencing engineers, scientists and aiding in the hyper-development of computer related activities. A salute to the filmmakers from one who was there - you\\'ve captured the era better than I\\'ve seen before.'\n",
            " 1]\n",
            "['I\\'m 14 years old and I love this cartoon. Burt Reynolds and Dom Deluise make a great pair. This movie is really funny and I love the songs. My favorite songs are \"You can\\'t keep a good dog down\" and that song about sharing, I think it\\'s called \"What\\'s mine is yours\". This was the last movie with Judith Barsi, who played the voice of Anne-Marie. My favorite character is Charlie but I find Itchy\\'s voice is so fun to hear. Although some scenes I actually found scary, I still have a hard time watching the scene with Charlie\\'s dream, and Carface scares the crap out of me. Other characters like King Gator I found really funny. The ending was adorable and was actually sad, made me cry a little. I give this movie 7/10.'\n",
            " 1]\n"
          ]
        }
      ],
      "source": [
        "for review in np.array(df_train)[np.array(df_train.sentiment) == 1][:5]:\n",
        "    print(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JPBJwkvDosN"
      },
      "source": [
        "## Procesamiento de texto\n",
        "\n",
        "Inicialmente crearemos una función para procesar y tokenizar el texto con las siguientes características:\n",
        "\n",
        "* Transformar el texto a minúsculas.\n",
        "* Eliminar caracteres que no sean letras. Para este problema de clasificación no parecen ser relevantes los caracteres puntuación, los números, ni caracteres especiales.\n",
        "* Solo conservamos tokens que contengan dos o más letras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfoZ5n1RDosN",
        "outputId": "edcbd81a-40ff-42ee-a98f-d57228a7740b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto original:\n",
            "In Panic In The Streets Richard Widmark plays U.S. Navy doctor who has his week rudely interrupted with a corpse that contains plague. As cop Paul Douglas properly points out the guy died from two bullets in the chest. That's not the issue here, the two of them become unwilling partners in an effort to find the killers and anyone else exposed to the disease.<br /><br />As was pointed out by any number of people, for some reason director Elia Kazan did not bother to cast the small parts with anyone that sounds like they're from Louisiana. Having been to New Orleans where the story takes place I can personally attest to that. Richard Widmark and his wife Barbara Bel Geddes can be excused because as a Navy doctor he could be assigned there, but for those that are natives it doesn't work.<br /><br />But with plague out there and the news being kept a secret, the New Orleans PD starts a dragnet of the city's underworld. The dead guy came off a ship from Europe and he had underworld connections. A New Orleans wise guy played by Jack Palance jumps to a whole bunch of erroneous conclusions and starts harassing a cousin of the dead guy who is starting to show plague symptoms. Palance got rave reviews in the first film where he received notice.<br /><br />Personally my favorite in this film is Zero Mostel. This happened right before Mostel was blacklisted and around that time he made a specialty of playing would be tough guys who are really toadies. He plays the same kind of role in the Humphrey Bogart film, The Enforcer. Sadly I can kind of identify with Mostel in that last chase scene where he and Palance are being chased down by Widmark, Douglas, and half the New Orleans Police. Seeing the weight challenged Zero trying to keep up with Palance was something else because I'm kind of in Zero's league now in the heft department.<br /><br />Kazan kept the action going at a good clip, there's very little down time in this film. If there was any less it would be an Indiana Jones film. Panic In The Streets won an Oscar for Best Original Screenplay that year.<br /><br />Kazan also made good use of the New Orleans waterfront and the French Quarter. Some of the same kinds of shots are later used in On the Waterfront. In fact Panic In The Streets is about people not squealing when they really should in their own best interest. Very similar again to On the Waterfront.<br /><br />Panic In The Streets does everyone proud who was associated with it. Now why couldn't Elia Kazan get some decent New Orleans sounding people in the small roles.\n",
            "Texto procesado y tokenizado:\n",
            "['in', 'panic', 'the', 'streets', 'richard', 'widmark', 'plays', 'navy', 'doctor', 'who', 'has', 'his', 'week', 'rudely', 'interrupted', 'with', 'corpse', 'that', 'contains', 'plague', 'cop', 'paul', 'douglas', 'properly', 'points', 'out', 'the', 'guy', 'died', 'from', 'two', 'bullets', 'the', 'chest', 'that', 'not', 'the', 'issue', 'here', 'the', 'two', 'them', 'become', 'unwilling', 'partners', 'effort', 'find', 'the', 'killers', 'and', 'anyone', 'else', 'exposed', 'the', 'disease', 'was', 'pointed', 'out', 'any', 'number', 'people', 'for', 'some', 'reason', 'director', 'elia', 'kazan', 'did', 'not', 'bother', 'cast', 'the', 'small', 'parts', 'with', 'anyone', 'that', 'sounds', 'like', 'they', 'from', 'louisiana', 'having', 'been', 'new', 'orleans', 'where', 'the', 'story', 'takes', 'place', 'can', 'personally', 'attest', 'that', 'richard', 'widmark', 'and', 'his', 'wife', 'barbara', 'bel', 'geddes', 'can', 'excused', 'because', 'navy', 'doctor', 'could', 'assigned', 'there', 'but', 'for', 'those', 'that', 'are', 'natives', 'doesn', 'work', 'but', 'with', 'plague', 'out', 'there', 'and', 'the', 'news', 'being', 'kept', 'secret', 'the', 'new', 'orleans', 'starts', 'dragnet', 'the', 'city', 'underworld', 'the', 'dead', 'guy', 'came', 'off', 'ship', 'from', 'europe', 'and', 'had', 'underworld', 'connections', 'new', 'orleans', 'wise', 'guy', 'played', 'jack', 'palance', 'jumps', 'whole', 'bunch', 'erroneous', 'conclusions', 'and', 'starts', 'harassing', 'cousin', 'the', 'dead', 'guy', 'who', 'starting', 'show', 'plague', 'symptoms', 'palance', 'got', 'rave', 'reviews', 'the', 'first', 'film', 'where', 'received', 'notice', 'personally', 'favorite', 'this', 'film', 'zero', 'mostel', 'this', 'happened', 'right', 'before', 'mostel', 'was', 'blacklisted', 'and', 'around', 'that', 'time', 'made', 'specialty', 'playing', 'would', 'tough', 'guys', 'who', 'are', 'really', 'toadies', 'plays', 'the', 'same', 'kind', 'role', 'the', 'humphrey', 'bogart', 'film', 'the', 'enforcer', 'sadly', 'can', 'kind', 'identify', 'with', 'mostel', 'that', 'last', 'chase', 'scene', 'where', 'and', 'palance', 'are', 'being', 'chased', 'down', 'widmark', 'douglas', 'and', 'half', 'the', 'new', 'orleans', 'police', 'seeing', 'the', 'weight', 'challenged', 'zero', 'trying', 'keep', 'with', 'palance', 'was', 'something', 'else', 'because', 'kind', 'zero', 'league', 'now', 'the', 'heft', 'department', 'kazan', 'kept', 'the', 'action', 'going', 'good', 'clip', 'there', 'very', 'little', 'down', 'time', 'this', 'film', 'there', 'was', 'any', 'less', 'would', 'indiana', 'jones', 'film', 'panic', 'the', 'streets', 'won', 'oscar', 'for', 'best', 'original', 'screenplay', 'that', 'year', 'kazan', 'also', 'made', 'good', 'use', 'the', 'new', 'orleans', 'waterfront', 'and', 'the', 'french', 'quarter', 'some', 'the', 'same', 'kinds', 'shots', 'are', 'later', 'used', 'the', 'waterfront', 'fact', 'panic', 'the', 'streets', 'about', 'people', 'not', 'squealing', 'when', 'they', 'really', 'should', 'their', 'own', 'best', 'interest', 'very', 'similar', 'again', 'the', 'waterfront', 'panic', 'the', 'streets', 'does', 'everyone', 'proud', 'who', 'was', 'associated', 'with', 'now', 'why', 'couldn', 'elia', 'kazan', 'get', 'some', 'decent', 'new', 'orleans', 'sounding', 'people', 'the', 'small', 'roles']\n"
          ]
        }
      ],
      "source": [
        "def tokenize_text(text: str) -> \"list[str]\":\n",
        "    \"\"\"\n",
        "    Procesa un texto y luego lo tokeniza.\n",
        "\n",
        "    Args:\n",
        "        text(str) texto a procesar y tokenizar.\n",
        "\n",
        "    Returns:\n",
        "        list[str] lista de tokens.\n",
        "    \"\"\"\n",
        "    text = re.sub(r'[^a-z]', ' ', text.lower()) # Convertir a minúsculas y eliminar caracteres no alfabéticos\n",
        "    text = re.sub(r'\\s[a-z]([a-z])?\\b', '', text) # Eliminar palabras de una o dos letras\n",
        "    return text.split() # Tokenizar\n",
        "\n",
        "\n",
        "sample = df_train.iloc[0].review\n",
        "print('Texto original:')\n",
        "print(sample)\n",
        "print('Texto procesado y tokenizado:')\n",
        "print(tokenize_text(sample))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUOFXd6cDosN"
      },
      "source": [
        "Podemos constuir el vocabulario de nuestro corpus de entrenamiento. Este tamaño sería el tamaño que tendría la representación de bolsa de palabras para cada uno de los documentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0hnBaydDosN",
        "outputId": "7ebd6801-1364-45e7-e6c3-bc9a2e657a6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de tokens únicos: 72866\n"
          ]
        }
      ],
      "source": [
        "vocabulary = {}\n",
        "for r in np.array(df_train):\n",
        "    #print(r[0])\n",
        "    for token in tokenize_text(r[0]):\n",
        "        vocabulary[token] = vocabulary.get(token, 0) + 1\n",
        "\n",
        "print(f'Número de tokens únicos: {len(vocabulary)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh7b8uACDosO"
      },
      "source": [
        "Podemos ver los tokens más frecuentes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDE5OSNBDosO",
        "outputId": "baf093f9-4545-4956-cd3b-0b630109d571"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 336758),\n",
              " ('and', 164143),\n",
              " ('this', 76007),\n",
              " ('that', 73287),\n",
              " ('was', 48209),\n",
              " ('for', 44345),\n",
              " ('with', 44130),\n",
              " ('movie', 44047),\n",
              " ('but', 42624),\n",
              " ('film', 40162)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Ver los 10 tokens más frecuentes\n",
        "sorted(vocabulary.items(), key=lambda x: x[1], reverse=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzghxwaTDosO"
      },
      "source": [
        "Estas tokens no parecen estar relacionados con el sentimiento de la reseña, por lo que podríamos eliminar los más frecuentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDn0IwYIDosO",
        "outputId": "9540a4d8-62a9-40c4-c5a8-07f087da5b1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('toadies', 1),\n",
              " ('heft', 1),\n",
              " ('loosy', 1),\n",
              " ('compaer', 1),\n",
              " ('reactionaries', 1),\n",
              " ('enshrine', 1),\n",
              " ('changin', 1),\n",
              " ('acceptably', 1),\n",
              " ('talmadges', 1),\n",
              " ('yeast', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sorted(vocabulary.items(), key=lambda x: x[1])[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5BLUowkDosO"
      },
      "source": [
        "Por otro lado los tokens menos frecuentes parecen ser nombres de películas, personajes, actores, entre otros, que tampoco parecen estar relacionados con la tarea de clasificación de sentimientos.\n",
        "\n",
        "# 2. Uso de Lexicones\n",
        "\n",
        "Adicionalmente a las representaciones de bolsa de palabras vistas en semanas anteriores. Podemos construir otro tipo de características que nosotros o expertos en el dominio de la tarea consideren relevantes para la solución del problema.\n",
        "\n",
        "En el caso de análisis de sentimiento existen diferentes lexicones en los que podemos encontrar la connotación negativa o positiva de las palabras. En esta sección utilizaremos el **Lexico Afinn del usuario de github jboscomendoza** que puede descargarse [aquí](https://raw.githubusercontent.com/jboscomendoza/lexicos-nrc-afinn/refs/heads/master/lexico_afinn.csv).\n",
        "\n",
        "Primero extraigamos los archivos correspondientes al lexicon descargado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SSFPefpKDosO"
      },
      "outputs": [],
      "source": [
        "#lexicon = pd.read_csv('./data/lexico_afinn.csv')\n",
        "#lexicon.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO8vHA6uDosO",
        "outputId": "35957562-58a5-48b0-d1be-76cc7e2319b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative\n",
            "\n",
            "type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative\n",
            "\n",
            "type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative\n",
            "\n",
            "type=strongsubj len=1 word1=abase pos1=verb stemmed1=y priorpolarity=negative\n",
            "\n",
            "type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y priorpolarity=negative\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open('data/subjclueslen1-HLTEMNLP05.tff') as f:\n",
        "    lexicon = f.readlines()\n",
        "\n",
        "for line in lexicon[:5]:\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQp-y7lGDosP"
      },
      "source": [
        "Según la documentación del lexicon, se resaltan las siguientes características:\n",
        "\n",
        "* palabra: Contiene la palabra en español.\n",
        "* puntuacion: Contiene la puntuación de la palabra en español que corresponde a la polaridad de la palabra, ya sea negativa, positiva o neutral, representada por numeros enteros que pueden ser positivos negativos o cero y cuyo valor indica mayor o menor subjetividad en el contexto.\n",
        "* word: Contiene la palabra en inglés.\n",
        "\n",
        "Uno de los grupos más simples de características que podemos extraer sobre el texto es la cantidad de palabras negativas y positivas que contiene. Así que primero podemos almacener de una manera conveniente los sets de palabras negativas y positivas contenidas en el lexicón."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sU37SvOJDosP"
      },
      "outputs": [],
      "source": [
        "#negative_words = set()\n",
        "#positive_words = set()\n",
        "\n",
        "# Iteramos sobre las filas del lexicon\n",
        "#for line in np.array(lexicon):\n",
        "    # Extraemos la palabra y la polaridad de la línea\n",
        "    #word = re.search(r'word1=(\\w+)', line).group(1)\n",
        "#    word = line[0]\n",
        "#    polarity = line[1]\n",
        "    # Guardamos la palabra en el conjunto correspondiente\n",
        "#    if polarity <= 0:\n",
        "#        negative_words.add(word)\n",
        "#    else:\n",
        "#print(\"Cantidad de palabras positivas:\", len(positive_words))\n",
        "#print(\"Cantidad de palabras negativas:\", len(negative_words))\n",
        "# Ver las primeras 10 palabras positivas\n",
        "#print(f'10 palabras positivas: {list(positive_words)[:10]}')\n",
        "# Ver las primeras 10 palabras negativas\n",
        "#print(f'10 palabras negativas: {list(negative_words)[:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfpLTa5mDosP",
        "outputId": "e3f36fbd-6fef-4621-fbcf-f87f3a3239f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palabras positivas: 2267\n",
            "Número de palabras negativas: 4103\n",
            "10 palabras positivas: ['meaningful', 'ingeniously', 'upheld', 'boast', 'enthusiastic', 'insist', 'preponderance', 'sanctify', 'ardent', 'devotee']\n",
            "10 palabras negativas: ['hellion', 'inaction', 'stupify', 'stricken', 'inadverent', 'denial', 'boast', 'mishandle', 'squash', 'hamstrung']\n"
          ]
        }
      ],
      "source": [
        "negative_words = set()\n",
        "positive_words = set()\n",
        "\n",
        "# Iteramos sobre las líneas del lexicon\n",
        "for line in lexicon:\n",
        "    # Extraemos la palabra y la polaridad de la línea\n",
        "    word = re.search(r'word1=(\\w+)', line).group(1)\n",
        "    polarity = re.search(r'priorpolarity=(\\w+)', line).group(1)\n",
        "    # Guardamos la palabra en el conjunto correspondiente\n",
        "    if polarity == 'negative':\n",
        "        negative_words.add(word)\n",
        "    if polarity == 'positive':\n",
        "        positive_words.add(word)\n",
        "\n",
        "print(f'Número de palabras positivas: {len(positive_words)}')\n",
        "print(f'Número de palabras negativas: {len(negative_words)}')\n",
        "\n",
        "# Ver las primeras 10 palabras positivas\n",
        "print(f'10 palabras positivas: {list(positive_words)[:10]}')\n",
        "# Ver las primeras 10 palabras negativas\n",
        "print(f'10 palabras negativas: {list(negative_words)[:10]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWI9vq3uDosP"
      },
      "source": [
        "Construyamos una clase similar a `CountVectorizer`de **scikit-learn** que nos permita extraer las características que definamos para cada documento del corpus.\n",
        "\n",
        "En este ejemplo vamos a extraer únicamente el número de palabras positivas y negativas contenidas en cada documento según el lexicón que estamos usando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF7TK_YcDosP",
        "outputId": "0201f4d3-f8e3-421d-87ff-692241e4cafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representación vectorial de las primeras 5 reseñas:\n",
            "[[23 23]\n",
            " [17 16]\n",
            " [22  5]\n",
            " [10 11]\n",
            " [ 9  5]]\n"
          ]
        }
      ],
      "source": [
        "class LexiconVectorizer:\n",
        "    def __init__(self, positive_words: set, negative_words: set):\n",
        "        \"\"\"\n",
        "        Este vectorizador cuenta la cantidad de palabras positivas y negativas en un texto según los sets de palabras positivas y negativas con que se inicialice.\n",
        "\n",
        "        Args:\n",
        "            positive_words(set[str]): conjunto de palabras positivas.\n",
        "            negative_words(set[str]): conjunto de palabras negativas.\n",
        "        \"\"\"\n",
        "        self.positive_words = positive_words\n",
        "        self.negative_words = negative_words\n",
        "\n",
        "    # Esta vectorizador no utiliza los datos de entrenamiento, por lo que el método fit solo retorna self\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Este método transforma una lista de textos en una matriz de numpy donde cada fila es la cantidad de palabras positivas y negativas en el texto correspondiente.\n",
        "\n",
        "        Args:\n",
        "            X(list[str]): lista de textos a transformar.\n",
        "\n",
        "        Returns:\n",
        "            np.array: matriz de numpy con la cantidad de palabras positivas y negativas en cada texto.\n",
        "        \"\"\"\n",
        "        docs = []\n",
        "        for doc in X:\n",
        "            docs.append(self.count_words(doc))\n",
        "\n",
        "        return np.array(docs)\n",
        "\n",
        "    def count_words(self, text: str) -> \"list[int]\":\n",
        "        \"\"\"\n",
        "        Este método cuenta la cantidad de palabras positivas y negativas en un texto.\n",
        "\n",
        "        Args:\n",
        "            text(str): texto a procesar.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: lista con la cantidad de palabras positivas y negativas en el texto.\n",
        "        \"\"\"\n",
        "        proccessed_text = tokenize_text(text)\n",
        "        positive_count = sum([1 for word in proccessed_text if word in self.positive_words])\n",
        "        negative_count = sum([1 for word in proccessed_text if word in self.negative_words])\n",
        "\n",
        "        return [positive_count, negative_count]\n",
        "\n",
        "    def fit_transform(self, X, y=None):\n",
        "        self.fit(X)\n",
        "        return self.transform(X)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"LexiconVectorizer()\"\n",
        "\n",
        "lexicon_vectorizer = LexiconVectorizer(positive_words, negative_words)\n",
        "X_train_lexicon = lexicon_vectorizer.fit_transform(df_train[\"review\"])\n",
        "print('Representación vectorial de las primeras 5 reseñas:')\n",
        "print(X_train_lexicon[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asF5WfHbDosP",
        "outputId": "5c84479a-dcee-4777-afe9-ceacf8153357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representación vectorial de la primera reseña:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 233 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "bow_vectorizer = CountVectorizer()\n",
        "X_train_bow = bow_vectorizer.fit_transform(df_train[\"review\"])\n",
        "print('Representación vectorial de la primera reseña:')\n",
        "X_train_bow[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtU9gNIbDosP"
      },
      "source": [
        "La representación de CountVectorizer consiste en una matriz dispersa de 462 dimensiones, con 240 dimensiones con un valor mayor a 0.\n",
        "\n",
        "Nosotros también podemos crear una representación de texto personalizada en la que usemos la tradicional bolsa de palabras junto con las características extraídas de los lexicones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrXBn6PLDosP",
        "outputId": "7f33cb20-1a8e-4589-9d51-679f4b39604e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Representación vectorial de la primera reseña:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x74851 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 235 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "class LexiconCountVectorizer(LexiconVectorizer):\n",
        "    def __init__(self, positive_words: set, negative_words: set, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Este vectorizador utiliza la representación generada por CountVectorizer junto con dos características sobre la proporción de palabras positivas y negativas identificadas en el documento.\n",
        "\n",
        "        Args:\n",
        "            positive_words(set[str]): conjunto de palabras positivas.\n",
        "            negative_words(set[str]): conjunto de palabras negativas.\n",
        "        \"\"\"\n",
        "        # Se inicializa la clase LexiconVectorizer\n",
        "        super().__init__(positive_words, negative_words)\n",
        "        # Se inicializa el CountVectorizer\n",
        "        self.count_vect = CountVectorizer(*args, **kwargs)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        Este método ajusta el vectorizador a los datos de entrenamiento.\n",
        "\n",
        "        Args:\n",
        "            X(list[str]): lista de textos de entrenamiento.\n",
        "            y: no se utiliza.\n",
        "\n",
        "        Returns:\n",
        "            LexiconCountVectorizer: retorna el objeto actual.\n",
        "        \"\"\"\n",
        "        # Se ajusta el CountVectorizer a los datos de entrenamiento\n",
        "        self.count_vect.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        Este método transforma una lista de textos en una matriz de numpy donde cada fila contiene las características extraídas de cada documento.\n",
        "\n",
        "        Args:\n",
        "            X(list[str]): lista de textos a transformar.\n",
        "\n",
        "        Returns:\n",
        "            np.array: matriz de numpy con la representación vectorial de cada documento.\n",
        "        \"\"\"\n",
        "        # Generar la representación de bolsa de palabras de los documentos\n",
        "        bow = self.count_vect.transform(X)\n",
        "\n",
        "        # Generar las características de palabras positivas y negativas de los documentos\n",
        "        lexicon_features = []\n",
        "        for doc in X:\n",
        "            lexicon_features.append(self.count_words(doc))\n",
        "\n",
        "        # Se cálcula la proporción de palabras positivas y negativas en cada documento\n",
        "        lexicon_features = np.array(lexicon_features) / (np.sum(lexicon_features, axis=1).reshape(-1, 1) + 0.01) # Se suma 0.01 para evitar divisiones por cero\n",
        "        # Se convierte a una matriz dispersa del mismo tipo que la matriz de bolsa de palabras\n",
        "        lexicon_features = scipy.sparse.csr_matrix(lexicon_features)\n",
        "\n",
        "        # Se concatenan las características de bolsa de palabras y las características de palabras positivas y negativas\n",
        "        return scipy.sparse.hstack([lexicon_features, bow], format='csr')\n",
        "\n",
        "    # set_params es un método utilizado por GridSearchCV para ajustar los parámetros del vectorizador\n",
        "    def set_params(self, **params):\n",
        "        \"\"\"\n",
        "        Este método ajusta los parámetros del CountVectorizer.\n",
        "\n",
        "        Args:\n",
        "            **params: parámetros a ajustar.\n",
        "\n",
        "        Returns:\n",
        "            LexiconCountVectorizer: retorna el objeto actual.\n",
        "        \"\"\"\n",
        "        self.count_vect.set_params(**params)\n",
        "        return self\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"LexiconCountVectorizer()\"\n",
        "\n",
        "# Prueba del vectorizador\n",
        "bow_vectorizer = LexiconCountVectorizer(positive_words, negative_words)\n",
        "X_train_bow = bow_vectorizer.fit_transform(df_train[\"review\"])\n",
        "print('Representación vectorial de la primera reseña:')\n",
        "X_train_bow[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWUVb6umDosQ"
      },
      "source": [
        "Note como el resultado del vectorizador para la primera reseña tiene 2 dimensiones más que la representación de bolsa de palabras realizada en la celda anterior con `CountVectorizer`, y además la matriz dispersa contiene ahora 94 valores mayores a 0 en vez de 92.\n",
        "\n",
        "Ahora observe los valores contenidos en la representación vectorial del primer documento del corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fcv9VyYDosQ",
        "outputId": "441341c4-63a0-47e1-d1ba-0ac32187d0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t0.49989132797218\n",
            "  (0, 1)\t0.49989132797218\n",
            "  (0, 1279)\t1.0\n",
            "  (0, 1630)\t1.0\n",
            "  (0, 2150)\t1.0\n",
            "  (0, 2823)\t1.0\n",
            "  (0, 3169)\t3.0\n",
            "  (0, 3260)\t9.0\n",
            "  (0, 3705)\t2.0\n",
            "  (0, 3717)\t2.0\n",
            "  (0, 4126)\t4.0\n",
            "  (0, 4299)\t1.0\n",
            "  (0, 4467)\t3.0\n",
            "  (0, 4639)\t1.0\n",
            "  (0, 4660)\t1.0\n",
            "  (0, 4755)\t1.0\n",
            "  (0, 4894)\t1.0\n",
            "  (0, 5918)\t1.0\n",
            "  (0, 6336)\t4.0\n",
            "  (0, 6461)\t2.0\n",
            "  (0, 6484)\t1.0\n",
            "  (0, 6545)\t1.0\n",
            "  (0, 6581)\t1.0\n",
            "  (0, 6665)\t2.0\n",
            "  (0, 6684)\t1.0\n",
            "  :\t:\n",
            "  (0, 68771)\t2.0\n",
            "  (0, 69435)\t2.0\n",
            "  (0, 70308)\t1.0\n",
            "  (0, 70333)\t1.0\n",
            "  (0, 70507)\t1.0\n",
            "  (0, 70508)\t1.0\n",
            "  (0, 71161)\t2.0\n",
            "  (0, 72198)\t5.0\n",
            "  (0, 72283)\t3.0\n",
            "  (0, 72454)\t1.0\n",
            "  (0, 72499)\t1.0\n",
            "  (0, 72755)\t1.0\n",
            "  (0, 72759)\t3.0\n",
            "  (0, 72906)\t4.0\n",
            "  (0, 72913)\t1.0\n",
            "  (0, 72967)\t1.0\n",
            "  (0, 73006)\t3.0\n",
            "  (0, 73030)\t1.0\n",
            "  (0, 73289)\t1.0\n",
            "  (0, 73344)\t6.0\n",
            "  (0, 73493)\t1.0\n",
            "  (0, 73618)\t1.0\n",
            "  (0, 73716)\t2.0\n",
            "  (0, 74149)\t1.0\n",
            "  (0, 74611)\t3.0\n"
          ]
        }
      ],
      "source": [
        "print(X_train_bow[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWoOnc24DosQ"
      },
      "source": [
        "# 3. Entrenamiento de clasificadores de texto\n",
        "\n",
        "En esta sección usaremos los clasificadores de **regresión logística** y **naive bayes** para clasificar el sentimiento de nuestras reseñas de películas. Vamos a probar distintas representaciones de texto para encontrar el modelo que mejor se ajusta a nuestro problema. Para realizar estas pruebas de manera conveniente vamos a utilizar `GridSearch` que nos permite poner a prueba el desempeño de distintos pipelines, y distintos hiperparámetros. Adicionalmente `GridSearch` utiliza validación cruzada para medir el desempeño de los modelos de una manera más robusta.\n",
        "\n",
        "Consulte la siguiente guía para conocer otras técnicas de ajuste de hiperparámetros, y para entender mejor su funcionamiento. [Link a la guía](https://scikit-learn.org/stable/modules/grid_search.html#tips-for-parameter-search).\n",
        "\n",
        "**Advertencia**: La ejecución de esta celda puede tardar más de 30 minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vAl3Sr64DosQ"
      },
      "outputs": [],
      "source": [
        "list_train_reviews = list(df_train[\"review\"])\n",
        "list_train_labels = list(df_train[\"sentiment\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8RMTYS3DosQ",
        "outputId": "36e070f4-0b32-46e5-e25a-f12896f25947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor configuración:\n",
            "{'classifier': LogisticRegression(max_iter=1000), 'representation': TfidfVectorizer(), 'representation__max_df': 0.9, 'representation__min_df': 1}\n",
            "\n",
            "Mejor puntaje de validación cruzada: 0.89\n"
          ]
        }
      ],
      "source": [
        "# Definimos la secuencia de pasos del pipeline que en este caso consiste en un vectorizador y un clasificador\n",
        "pipeline = Pipeline([\n",
        "    ('representation', CountVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Definimos el espacio de búsqueda para cada paso del pipeline\n",
        "# Definimos el espacio de búsqueda como una lista de diccionarios si queremos probar diferentes hipérparámetros por configuración\n",
        "param_grid = [\n",
        "    # Probamos diferentes configuraciones  y adicionalmente probamos diferentes hipérparámetros para los vectorizadores\n",
        "    {\n",
        "    'representation': [CountVectorizer(), TfidfVectorizer(), LexiconCountVectorizer(positive_words, negative_words)],\n",
        "    'representation__max_df': [0.8, 0.9, 1.0],\n",
        "    'representation__min_df': [0.1, 0.5, 1],\n",
        "    'classifier': [MultinomialNB(), LogisticRegression(max_iter=1000)],\n",
        "    }\n",
        "]\n",
        "\n",
        "# Realizamos la búsqueda de hiperparámetros\n",
        "search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "search.fit(list_train_reviews, list_train_labels)\n",
        "\n",
        "print(\"Mejor configuración:\\n{}\\n\".format(search.best_params_))\n",
        "print(\"Mejor puntaje de validación cruzada: {:.2f}\".format(search.best_score_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVByxC0qDosR"
      },
      "source": [
        "La busqueda de hiperparámetros nos indica que la configuración que mejor resultados en promedio obtuvo fue la representación generada por `TfidfVectorizer`, en la que se utilizan todas las palabras del vocabulario ('representation__max_df': 1.0, y 'representation__min_df': 0) con un clasificador de regresión logística. En promedio esta configuración obtuvo un 89% de accuracy en las 5 particiones de evaluación generadas.\n",
        "\n",
        "Adicionalmente, la clase `GridSearchCV` posee el atributo `cv_results_` en donde podemos ver todos los resultados obtenidos para cada configuración probada. Este diccionario puede leerse fácilmente como un `DataFrame` de **pandas**, y darnos información importante como la duración del entrenamiento (en segundos), los parámetros probados en la configuración, y los puntajes obtenidos de entrenamiento y de evaluación por cada uno de las particiones realizadas de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y-01lxkUDosS",
        "outputId": "91b40073-097e-442e-f33b-ec99ec3941bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "41       3.910302      0.448197         1.789055        0.362416   \n",
              "38       4.130929      0.433839         1.677191        0.113126   \n",
              "44       4.124476      0.376111         1.591765        0.126292   \n",
              "53      15.212402      2.707447         2.829509        0.682876   \n",
              "50      14.201265      0.230822         3.430916        0.369254   \n",
              "32       7.561887      0.784268         1.682757        0.017900   \n",
              "35      11.196429      0.131445         1.691602        0.089959   \n",
              "47      13.055122      0.291876         3.451577        0.255403   \n",
              "29       6.762593      0.502872         1.589417        0.054673   \n",
              "11       3.538821      0.151297         1.774729        0.264553   \n",
              "14       3.644890      0.368681         1.544347        0.059072   \n",
              "17       3.721461      0.321954         1.529496        0.038423   \n",
              "20      10.179744      0.097930         3.127814        0.047321   \n",
              "2        3.428316      0.389160         1.563856        0.029957   \n",
              "23      10.072208      0.060853         3.320687        0.285380   \n",
              "5        3.282768      0.054662         1.580130        0.049137   \n",
              "26       9.675498      0.299684         3.762366        0.194814   \n",
              "8        3.250545      0.199842         1.495884        0.029886   \n",
              "51       9.785425      0.365411         3.095013        0.352687   \n",
              "48       9.682409      0.252482         3.243897        0.282886   \n",
              "45       9.470215      0.246694         3.356298        0.375366   \n",
              "42       3.170824      0.058694         1.255547        0.022673   \n",
              "39       3.172716      0.067539         1.326367        0.058803   \n",
              "33       3.637762      0.282379         1.737602        0.351538   \n",
              "30       3.537845      0.424489         1.385413        0.169067   \n",
              "36       3.524537      0.567602         1.615318        0.295759   \n",
              "27       3.238931      0.102831         1.440810        0.210416   \n",
              "15       2.991598      0.032361         1.546140        0.216549   \n",
              "9        3.564415      0.348996         1.340141        0.024678   \n",
              "12       3.278156      0.366161         1.442438        0.231156   \n",
              "18       9.349218      0.085721         2.975241        0.106117   \n",
              "0        4.069425      0.809713         1.380283        0.102341   \n",
              "21       9.477596      0.088593         2.911476        0.089726   \n",
              "52       8.970814      0.451121         3.230658        0.304344   \n",
              "24       9.333967      0.328722         3.115958        0.285102   \n",
              "3        3.286469      0.367983         1.335949        0.031967   \n",
              "6        3.532818      0.418711         1.264563        0.027556   \n",
              "49       8.646520      0.278899         3.608669        0.158158   \n",
              "46       9.341679      0.388294         3.029108        0.258084   \n",
              "43       3.500031      0.347219         1.327843        0.110454   \n",
              "34       3.026587      0.058952         1.342796        0.058941   \n",
              "25       8.864776      0.158237         3.281153        0.379659   \n",
              "16       3.181335      0.139411         1.258011        0.029660   \n",
              "7        3.085138      0.105993         1.595813        0.265521   \n",
              "40       3.567600      0.325877         1.255680        0.011307   \n",
              "31       3.412358      0.332227         1.351151        0.094656   \n",
              "22       9.305527      0.119190         2.827225        0.040946   \n",
              "19       9.400665      0.126330         2.890951        0.049086   \n",
              "13       2.971872      0.087745         1.272841        0.019742   \n",
              "28       3.049830      0.037506         1.445390        0.288852   \n",
              "4        3.041712      0.065442         1.623191        0.302372   \n",
              "37       3.333887      0.372279         1.258518        0.021621   \n",
              "10       3.004072      0.034164         1.519010        0.324251   \n",
              "1        4.060157      1.041363         1.451717        0.225458   \n",
              "\n",
              "                     param_classifier      param_representation  \\\n",
              "41  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "38  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "44  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "53  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "50  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "32  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "35  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "47  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "29  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "11                    MultinomialNB()         TfidfVectorizer()   \n",
              "14                    MultinomialNB()         TfidfVectorizer()   \n",
              "17                    MultinomialNB()         TfidfVectorizer()   \n",
              "20                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "2                     MultinomialNB()         CountVectorizer()   \n",
              "23                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "5                     MultinomialNB()         CountVectorizer()   \n",
              "26                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "8                     MultinomialNB()         CountVectorizer()   \n",
              "51  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "48  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "45  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "42  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "39  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "33  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "30  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "36  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "27  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "15                    MultinomialNB()         TfidfVectorizer()   \n",
              "9                     MultinomialNB()         TfidfVectorizer()   \n",
              "12                    MultinomialNB()         TfidfVectorizer()   \n",
              "18                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "0                     MultinomialNB()         CountVectorizer()   \n",
              "21                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "52  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "24                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "3                     MultinomialNB()         CountVectorizer()   \n",
              "6                     MultinomialNB()         CountVectorizer()   \n",
              "49  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "46  LogisticRegression(max_iter=1000)  LexiconCountVectorizer()   \n",
              "43  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "34  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "25                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "16                    MultinomialNB()         TfidfVectorizer()   \n",
              "7                     MultinomialNB()         CountVectorizer()   \n",
              "40  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "31  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "22                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "19                    MultinomialNB()  LexiconCountVectorizer()   \n",
              "13                    MultinomialNB()         TfidfVectorizer()   \n",
              "28  LogisticRegression(max_iter=1000)         CountVectorizer()   \n",
              "4                     MultinomialNB()         CountVectorizer()   \n",
              "37  LogisticRegression(max_iter=1000)         TfidfVectorizer()   \n",
              "10                    MultinomialNB()         TfidfVectorizer()   \n",
              "1                     MultinomialNB()         CountVectorizer()   \n",
              "\n",
              "    param_representation__max_df  param_representation__min_df  \\\n",
              "41                           0.9                           1.0   \n",
              "38                           0.8                           1.0   \n",
              "44                           1.0                           1.0   \n",
              "53                           1.0                           1.0   \n",
              "50                           0.9                           1.0   \n",
              "32                           0.9                           1.0   \n",
              "35                           1.0                           1.0   \n",
              "47                           0.8                           1.0   \n",
              "29                           0.8                           1.0   \n",
              "11                           0.8                           1.0   \n",
              "14                           0.9                           1.0   \n",
              "17                           1.0                           1.0   \n",
              "20                           0.8                           1.0   \n",
              "2                            0.8                           1.0   \n",
              "23                           0.9                           1.0   \n",
              "5                            0.9                           1.0   \n",
              "26                           1.0                           1.0   \n",
              "8                            1.0                           1.0   \n",
              "51                           1.0                           0.1   \n",
              "48                           0.9                           0.1   \n",
              "45                           0.8                           0.1   \n",
              "42                           1.0                           0.1   \n",
              "39                           0.9                           0.1   \n",
              "33                           1.0                           0.1   \n",
              "30                           0.9                           0.1   \n",
              "36                           0.8                           0.1   \n",
              "27                           0.8                           0.1   \n",
              "15                           1.0                           0.1   \n",
              "9                            0.8                           0.1   \n",
              "12                           0.9                           0.1   \n",
              "18                           0.8                           0.1   \n",
              "0                            0.8                           0.1   \n",
              "21                           0.9                           0.1   \n",
              "52                           1.0                           0.5   \n",
              "24                           1.0                           0.1   \n",
              "3                            0.9                           0.1   \n",
              "6                            1.0                           0.1   \n",
              "49                           0.9                           0.5   \n",
              "46                           0.8                           0.5   \n",
              "43                           1.0                           0.5   \n",
              "34                           1.0                           0.5   \n",
              "25                           1.0                           0.5   \n",
              "16                           1.0                           0.5   \n",
              "7                            1.0                           0.5   \n",
              "40                           0.9                           0.5   \n",
              "31                           0.9                           0.5   \n",
              "22                           0.9                           0.5   \n",
              "19                           0.8                           0.5   \n",
              "13                           0.9                           0.5   \n",
              "28                           0.8                           0.5   \n",
              "4                            0.9                           0.5   \n",
              "37                           0.8                           0.5   \n",
              "10                           0.8                           0.5   \n",
              "1                            0.8                           0.5   \n",
              "\n",
              "                                               params  split0_test_score  \\\n",
              "41  {'classifier': LogisticRegression(max_iter=100...           0.888409   \n",
              "38  {'classifier': LogisticRegression(max_iter=100...           0.885289   \n",
              "44  {'classifier': LogisticRegression(max_iter=100...           0.886369   \n",
              "53  {'classifier': LogisticRegression(max_iter=100...           0.876770   \n",
              "50  {'classifier': LogisticRegression(max_iter=100...           0.877250   \n",
              "32  {'classifier': LogisticRegression(max_iter=100...           0.877370   \n",
              "35  {'classifier': LogisticRegression(max_iter=100...           0.877370   \n",
              "47  {'classifier': LogisticRegression(max_iter=100...           0.876890   \n",
              "29  {'classifier': LogisticRegression(max_iter=100...           0.876050   \n",
              "11  {'classifier': MultinomialNB(), 'representatio...           0.858171   \n",
              "14  {'classifier': MultinomialNB(), 'representatio...           0.857931   \n",
              "17  {'classifier': MultinomialNB(), 'representatio...           0.857451   \n",
              "20  {'classifier': MultinomialNB(), 'representatio...           0.843653   \n",
              "2   {'classifier': MultinomialNB(), 'representatio...           0.842453   \n",
              "23  {'classifier': MultinomialNB(), 'representatio...           0.843293   \n",
              "5   {'classifier': MultinomialNB(), 'representatio...           0.842573   \n",
              "26  {'classifier': MultinomialNB(), 'representatio...           0.842093   \n",
              "8   {'classifier': MultinomialNB(), 'representatio...           0.841733   \n",
              "51  {'classifier': LogisticRegression(max_iter=100...           0.802016   \n",
              "48  {'classifier': LogisticRegression(max_iter=100...           0.798776   \n",
              "45  {'classifier': LogisticRegression(max_iter=100...           0.795056   \n",
              "42  {'classifier': LogisticRegression(max_iter=100...           0.776218   \n",
              "39  {'classifier': LogisticRegression(max_iter=100...           0.773818   \n",
              "33  {'classifier': LogisticRegression(max_iter=100...           0.774538   \n",
              "30  {'classifier': LogisticRegression(max_iter=100...           0.771658   \n",
              "36  {'classifier': LogisticRegression(max_iter=100...           0.771538   \n",
              "27  {'classifier': LogisticRegression(max_iter=100...           0.772138   \n",
              "15  {'classifier': MultinomialNB(), 'representatio...           0.749700   \n",
              "9   {'classifier': MultinomialNB(), 'representatio...           0.749700   \n",
              "12  {'classifier': MultinomialNB(), 'representatio...           0.750540   \n",
              "18  {'classifier': MultinomialNB(), 'representatio...           0.732901   \n",
              "0   {'classifier': MultinomialNB(), 'representatio...           0.728702   \n",
              "21  {'classifier': MultinomialNB(), 'representatio...           0.729182   \n",
              "52  {'classifier': LogisticRegression(max_iter=100...           0.731701   \n",
              "24  {'classifier': MultinomialNB(), 'representatio...           0.725822   \n",
              "3   {'classifier': MultinomialNB(), 'representatio...           0.724742   \n",
              "6   {'classifier': MultinomialNB(), 'representatio...           0.724382   \n",
              "49  {'classifier': LogisticRegression(max_iter=100...           0.723542   \n",
              "46  {'classifier': LogisticRegression(max_iter=100...           0.715983   \n",
              "43  {'classifier': LogisticRegression(max_iter=100...           0.622750   \n",
              "34  {'classifier': LogisticRegression(max_iter=100...           0.619750   \n",
              "25  {'classifier': MultinomialNB(), 'representatio...           0.610511   \n",
              "16  {'classifier': MultinomialNB(), 'representatio...           0.603072   \n",
              "7   {'classifier': MultinomialNB(), 'representatio...           0.598632   \n",
              "40  {'classifier': LogisticRegression(max_iter=100...           0.601752   \n",
              "31  {'classifier': LogisticRegression(max_iter=100...           0.599112   \n",
              "22  {'classifier': MultinomialNB(), 'representatio...           0.596712   \n",
              "19  {'classifier': MultinomialNB(), 'representatio...           0.591193   \n",
              "13  {'classifier': MultinomialNB(), 'representatio...           0.589753   \n",
              "28  {'classifier': LogisticRegression(max_iter=100...           0.581234   \n",
              "4   {'classifier': MultinomialNB(), 'representatio...           0.586633   \n",
              "37  {'classifier': LogisticRegression(max_iter=100...           0.579074   \n",
              "10  {'classifier': MultinomialNB(), 'representatio...           0.576434   \n",
              "1   {'classifier': MultinomialNB(), 'representatio...           0.574634   \n",
              "\n",
              "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "41           0.881675           0.887315          0.88580        0.002951   \n",
              "38           0.881075           0.888276          0.88488        0.002954   \n",
              "44           0.879035           0.888276          0.88456        0.003983   \n",
              "53           0.875315           0.878195          0.87676        0.001176   \n",
              "50           0.875795           0.876995          0.87668        0.000634   \n",
              "32           0.875075           0.877115          0.87652        0.001027   \n",
              "35           0.874835           0.876995          0.87640        0.001117   \n",
              "47           0.875435           0.876515          0.87628        0.000617   \n",
              "29           0.873155           0.877355          0.87552        0.001755   \n",
              "11           0.859594           0.867275          0.86168        0.003998   \n",
              "14           0.858994           0.866795          0.86124        0.003952   \n",
              "17           0.858634           0.866915          0.86100        0.004210   \n",
              "20           0.852514           0.855634          0.85060        0.005075   \n",
              "2            0.852274           0.855754          0.85016        0.005632   \n",
              "23           0.851314           0.854554          0.84972        0.004734   \n",
              "5            0.851194           0.854314          0.84936        0.004966   \n",
              "26           0.850834           0.853234          0.84872        0.004788   \n",
              "8            0.849994           0.852634          0.84812        0.004644   \n",
              "51           0.807872           0.797192          0.80236        0.004367   \n",
              "48           0.806552           0.797552          0.80096        0.003986   \n",
              "45           0.803672           0.795392          0.79804        0.003985   \n",
              "42           0.772471           0.772711          0.77380        0.001713   \n",
              "39           0.768631           0.773191          0.77188        0.002312   \n",
              "33           0.769951           0.769831          0.77144        0.002191   \n",
              "30           0.768151           0.770911          0.77024        0.001508   \n",
              "36           0.763471           0.769711          0.76824        0.003454   \n",
              "27           0.763231           0.767311          0.76756        0.003641   \n",
              "15           0.744270           0.753270          0.74908        0.003700   \n",
              "9            0.737429           0.752310          0.74648        0.006488   \n",
              "12           0.735869           0.751950          0.74612        0.007271   \n",
              "18           0.730829           0.735629          0.73312        0.001966   \n",
              "0            0.727229           0.732389          0.72944        0.002170   \n",
              "21           0.725669           0.731309          0.72872        0.002326   \n",
              "52           0.733109           0.717269          0.72736        0.007159   \n",
              "24           0.725429           0.727229          0.72616        0.000773   \n",
              "3            0.722309           0.727469          0.72484        0.002108   \n",
              "6            0.723869           0.723749          0.72400        0.000275   \n",
              "49           0.722189           0.710788          0.71884        0.005720   \n",
              "46           0.717509           0.704428          0.71264        0.005840   \n",
              "43           0.621145           0.621985          0.62196        0.000656   \n",
              "34           0.619945           0.623665          0.62112        0.001801   \n",
              "25           0.616465           0.608184          0.61172        0.003487   \n",
              "16           0.603744           0.609144          0.60532        0.002718   \n",
              "7            0.606504           0.598584          0.60124        0.003722   \n",
              "40           0.598944           0.603024          0.60124        0.001705   \n",
              "31           0.599064           0.601824          0.60000        0.001290   \n",
              "22           0.596304           0.598824          0.59728        0.001104   \n",
              "19           0.595824           0.591984          0.59300        0.002023   \n",
              "13           0.582743           0.592824          0.58844        0.004219   \n",
              "28           0.589344           0.588984          0.58652        0.003741   \n",
              "4            0.584903           0.587544          0.58636        0.001095   \n",
              "37           0.585263           0.586943          0.58376        0.003384   \n",
              "10           0.578063           0.580223          0.57824        0.001552   \n",
              "1            0.577463           0.572423          0.57484        0.002063   \n",
              "\n",
              "    rank_test_score  \n",
              "41                1  \n",
              "38                2  \n",
              "44                3  \n",
              "53                4  \n",
              "50                5  \n",
              "32                6  \n",
              "35                7  \n",
              "47                8  \n",
              "29                9  \n",
              "11               10  \n",
              "14               11  \n",
              "17               12  \n",
              "20               13  \n",
              "2                14  \n",
              "23               15  \n",
              "5                16  \n",
              "26               17  \n",
              "8                18  \n",
              "51               19  \n",
              "48               20  \n",
              "45               21  \n",
              "42               22  \n",
              "39               23  \n",
              "33               24  \n",
              "30               25  \n",
              "36               26  \n",
              "27               27  \n",
              "15               28  \n",
              "9                29  \n",
              "12               30  \n",
              "18               31  \n",
              "0                32  \n",
              "21               33  \n",
              "52               34  \n",
              "24               35  \n",
              "3                36  \n",
              "6                37  \n",
              "49               38  \n",
              "46               39  \n",
              "43               40  \n",
              "34               41  \n",
              "25               42  \n",
              "16               43  \n",
              "7                44  \n",
              "40               45  \n",
              "31               46  \n",
              "22               47  \n",
              "19               48  \n",
              "13               49  \n",
              "28               50  \n",
              "4                51  \n",
              "37               52  \n",
              "10               53  \n",
              "1                54  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-135cd3b5-4d58-43fb-9f12-cab144ffbe31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_classifier</th>\n",
              "      <th>param_representation</th>\n",
              "      <th>param_representation__max_df</th>\n",
              "      <th>param_representation__min_df</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>3.910302</td>\n",
              "      <td>0.448197</td>\n",
              "      <td>1.789055</td>\n",
              "      <td>0.362416</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.888409</td>\n",
              "      <td>0.881675</td>\n",
              "      <td>0.887315</td>\n",
              "      <td>0.88580</td>\n",
              "      <td>0.002951</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>4.130929</td>\n",
              "      <td>0.433839</td>\n",
              "      <td>1.677191</td>\n",
              "      <td>0.113126</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.885289</td>\n",
              "      <td>0.881075</td>\n",
              "      <td>0.888276</td>\n",
              "      <td>0.88488</td>\n",
              "      <td>0.002954</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4.124476</td>\n",
              "      <td>0.376111</td>\n",
              "      <td>1.591765</td>\n",
              "      <td>0.126292</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.886369</td>\n",
              "      <td>0.879035</td>\n",
              "      <td>0.888276</td>\n",
              "      <td>0.88456</td>\n",
              "      <td>0.003983</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>15.212402</td>\n",
              "      <td>2.707447</td>\n",
              "      <td>2.829509</td>\n",
              "      <td>0.682876</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.876770</td>\n",
              "      <td>0.875315</td>\n",
              "      <td>0.878195</td>\n",
              "      <td>0.87676</td>\n",
              "      <td>0.001176</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>14.201265</td>\n",
              "      <td>0.230822</td>\n",
              "      <td>3.430916</td>\n",
              "      <td>0.369254</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.877250</td>\n",
              "      <td>0.875795</td>\n",
              "      <td>0.876995</td>\n",
              "      <td>0.87668</td>\n",
              "      <td>0.000634</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>7.561887</td>\n",
              "      <td>0.784268</td>\n",
              "      <td>1.682757</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.877370</td>\n",
              "      <td>0.875075</td>\n",
              "      <td>0.877115</td>\n",
              "      <td>0.87652</td>\n",
              "      <td>0.001027</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>11.196429</td>\n",
              "      <td>0.131445</td>\n",
              "      <td>1.691602</td>\n",
              "      <td>0.089959</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.877370</td>\n",
              "      <td>0.874835</td>\n",
              "      <td>0.876995</td>\n",
              "      <td>0.87640</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>13.055122</td>\n",
              "      <td>0.291876</td>\n",
              "      <td>3.451577</td>\n",
              "      <td>0.255403</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.876890</td>\n",
              "      <td>0.875435</td>\n",
              "      <td>0.876515</td>\n",
              "      <td>0.87628</td>\n",
              "      <td>0.000617</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>6.762593</td>\n",
              "      <td>0.502872</td>\n",
              "      <td>1.589417</td>\n",
              "      <td>0.054673</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.876050</td>\n",
              "      <td>0.873155</td>\n",
              "      <td>0.877355</td>\n",
              "      <td>0.87552</td>\n",
              "      <td>0.001755</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3.538821</td>\n",
              "      <td>0.151297</td>\n",
              "      <td>1.774729</td>\n",
              "      <td>0.264553</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.858171</td>\n",
              "      <td>0.859594</td>\n",
              "      <td>0.867275</td>\n",
              "      <td>0.86168</td>\n",
              "      <td>0.003998</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.644890</td>\n",
              "      <td>0.368681</td>\n",
              "      <td>1.544347</td>\n",
              "      <td>0.059072</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.857931</td>\n",
              "      <td>0.858994</td>\n",
              "      <td>0.866795</td>\n",
              "      <td>0.86124</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.721461</td>\n",
              "      <td>0.321954</td>\n",
              "      <td>1.529496</td>\n",
              "      <td>0.038423</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.857451</td>\n",
              "      <td>0.858634</td>\n",
              "      <td>0.866915</td>\n",
              "      <td>0.86100</td>\n",
              "      <td>0.004210</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>10.179744</td>\n",
              "      <td>0.097930</td>\n",
              "      <td>3.127814</td>\n",
              "      <td>0.047321</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.843653</td>\n",
              "      <td>0.852514</td>\n",
              "      <td>0.855634</td>\n",
              "      <td>0.85060</td>\n",
              "      <td>0.005075</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.428316</td>\n",
              "      <td>0.389160</td>\n",
              "      <td>1.563856</td>\n",
              "      <td>0.029957</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.842453</td>\n",
              "      <td>0.852274</td>\n",
              "      <td>0.855754</td>\n",
              "      <td>0.85016</td>\n",
              "      <td>0.005632</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>10.072208</td>\n",
              "      <td>0.060853</td>\n",
              "      <td>3.320687</td>\n",
              "      <td>0.285380</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.843293</td>\n",
              "      <td>0.851314</td>\n",
              "      <td>0.854554</td>\n",
              "      <td>0.84972</td>\n",
              "      <td>0.004734</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.282768</td>\n",
              "      <td>0.054662</td>\n",
              "      <td>1.580130</td>\n",
              "      <td>0.049137</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.842573</td>\n",
              "      <td>0.851194</td>\n",
              "      <td>0.854314</td>\n",
              "      <td>0.84936</td>\n",
              "      <td>0.004966</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>9.675498</td>\n",
              "      <td>0.299684</td>\n",
              "      <td>3.762366</td>\n",
              "      <td>0.194814</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.842093</td>\n",
              "      <td>0.850834</td>\n",
              "      <td>0.853234</td>\n",
              "      <td>0.84872</td>\n",
              "      <td>0.004788</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3.250545</td>\n",
              "      <td>0.199842</td>\n",
              "      <td>1.495884</td>\n",
              "      <td>0.029886</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.841733</td>\n",
              "      <td>0.849994</td>\n",
              "      <td>0.852634</td>\n",
              "      <td>0.84812</td>\n",
              "      <td>0.004644</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>9.785425</td>\n",
              "      <td>0.365411</td>\n",
              "      <td>3.095013</td>\n",
              "      <td>0.352687</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.802016</td>\n",
              "      <td>0.807872</td>\n",
              "      <td>0.797192</td>\n",
              "      <td>0.80236</td>\n",
              "      <td>0.004367</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>9.682409</td>\n",
              "      <td>0.252482</td>\n",
              "      <td>3.243897</td>\n",
              "      <td>0.282886</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.798776</td>\n",
              "      <td>0.806552</td>\n",
              "      <td>0.797552</td>\n",
              "      <td>0.80096</td>\n",
              "      <td>0.003986</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>9.470215</td>\n",
              "      <td>0.246694</td>\n",
              "      <td>3.356298</td>\n",
              "      <td>0.375366</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.795056</td>\n",
              "      <td>0.803672</td>\n",
              "      <td>0.795392</td>\n",
              "      <td>0.79804</td>\n",
              "      <td>0.003985</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>3.170824</td>\n",
              "      <td>0.058694</td>\n",
              "      <td>1.255547</td>\n",
              "      <td>0.022673</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.776218</td>\n",
              "      <td>0.772471</td>\n",
              "      <td>0.772711</td>\n",
              "      <td>0.77380</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>3.172716</td>\n",
              "      <td>0.067539</td>\n",
              "      <td>1.326367</td>\n",
              "      <td>0.058803</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.773818</td>\n",
              "      <td>0.768631</td>\n",
              "      <td>0.773191</td>\n",
              "      <td>0.77188</td>\n",
              "      <td>0.002312</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>3.637762</td>\n",
              "      <td>0.282379</td>\n",
              "      <td>1.737602</td>\n",
              "      <td>0.351538</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.774538</td>\n",
              "      <td>0.769951</td>\n",
              "      <td>0.769831</td>\n",
              "      <td>0.77144</td>\n",
              "      <td>0.002191</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>3.537845</td>\n",
              "      <td>0.424489</td>\n",
              "      <td>1.385413</td>\n",
              "      <td>0.169067</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.771658</td>\n",
              "      <td>0.768151</td>\n",
              "      <td>0.770911</td>\n",
              "      <td>0.77024</td>\n",
              "      <td>0.001508</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>3.524537</td>\n",
              "      <td>0.567602</td>\n",
              "      <td>1.615318</td>\n",
              "      <td>0.295759</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.771538</td>\n",
              "      <td>0.763471</td>\n",
              "      <td>0.769711</td>\n",
              "      <td>0.76824</td>\n",
              "      <td>0.003454</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3.238931</td>\n",
              "      <td>0.102831</td>\n",
              "      <td>1.440810</td>\n",
              "      <td>0.210416</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.772138</td>\n",
              "      <td>0.763231</td>\n",
              "      <td>0.767311</td>\n",
              "      <td>0.76756</td>\n",
              "      <td>0.003641</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2.991598</td>\n",
              "      <td>0.032361</td>\n",
              "      <td>1.546140</td>\n",
              "      <td>0.216549</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.749700</td>\n",
              "      <td>0.744270</td>\n",
              "      <td>0.753270</td>\n",
              "      <td>0.74908</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.564415</td>\n",
              "      <td>0.348996</td>\n",
              "      <td>1.340141</td>\n",
              "      <td>0.024678</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.749700</td>\n",
              "      <td>0.737429</td>\n",
              "      <td>0.752310</td>\n",
              "      <td>0.74648</td>\n",
              "      <td>0.006488</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.278156</td>\n",
              "      <td>0.366161</td>\n",
              "      <td>1.442438</td>\n",
              "      <td>0.231156</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.750540</td>\n",
              "      <td>0.735869</td>\n",
              "      <td>0.751950</td>\n",
              "      <td>0.74612</td>\n",
              "      <td>0.007271</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>9.349218</td>\n",
              "      <td>0.085721</td>\n",
              "      <td>2.975241</td>\n",
              "      <td>0.106117</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.732901</td>\n",
              "      <td>0.730829</td>\n",
              "      <td>0.735629</td>\n",
              "      <td>0.73312</td>\n",
              "      <td>0.001966</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.069425</td>\n",
              "      <td>0.809713</td>\n",
              "      <td>1.380283</td>\n",
              "      <td>0.102341</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.728702</td>\n",
              "      <td>0.727229</td>\n",
              "      <td>0.732389</td>\n",
              "      <td>0.72944</td>\n",
              "      <td>0.002170</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>9.477596</td>\n",
              "      <td>0.088593</td>\n",
              "      <td>2.911476</td>\n",
              "      <td>0.089726</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.729182</td>\n",
              "      <td>0.725669</td>\n",
              "      <td>0.731309</td>\n",
              "      <td>0.72872</td>\n",
              "      <td>0.002326</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>8.970814</td>\n",
              "      <td>0.451121</td>\n",
              "      <td>3.230658</td>\n",
              "      <td>0.304344</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.731701</td>\n",
              "      <td>0.733109</td>\n",
              "      <td>0.717269</td>\n",
              "      <td>0.72736</td>\n",
              "      <td>0.007159</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>9.333967</td>\n",
              "      <td>0.328722</td>\n",
              "      <td>3.115958</td>\n",
              "      <td>0.285102</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.725822</td>\n",
              "      <td>0.725429</td>\n",
              "      <td>0.727229</td>\n",
              "      <td>0.72616</td>\n",
              "      <td>0.000773</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.286469</td>\n",
              "      <td>0.367983</td>\n",
              "      <td>1.335949</td>\n",
              "      <td>0.031967</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.724742</td>\n",
              "      <td>0.722309</td>\n",
              "      <td>0.727469</td>\n",
              "      <td>0.72484</td>\n",
              "      <td>0.002108</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.532818</td>\n",
              "      <td>0.418711</td>\n",
              "      <td>1.264563</td>\n",
              "      <td>0.027556</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.724382</td>\n",
              "      <td>0.723869</td>\n",
              "      <td>0.723749</td>\n",
              "      <td>0.72400</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>8.646520</td>\n",
              "      <td>0.278899</td>\n",
              "      <td>3.608669</td>\n",
              "      <td>0.158158</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.723542</td>\n",
              "      <td>0.722189</td>\n",
              "      <td>0.710788</td>\n",
              "      <td>0.71884</td>\n",
              "      <td>0.005720</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>9.341679</td>\n",
              "      <td>0.388294</td>\n",
              "      <td>3.029108</td>\n",
              "      <td>0.258084</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.715983</td>\n",
              "      <td>0.717509</td>\n",
              "      <td>0.704428</td>\n",
              "      <td>0.71264</td>\n",
              "      <td>0.005840</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>3.500031</td>\n",
              "      <td>0.347219</td>\n",
              "      <td>1.327843</td>\n",
              "      <td>0.110454</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.622750</td>\n",
              "      <td>0.621145</td>\n",
              "      <td>0.621985</td>\n",
              "      <td>0.62196</td>\n",
              "      <td>0.000656</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>3.026587</td>\n",
              "      <td>0.058952</td>\n",
              "      <td>1.342796</td>\n",
              "      <td>0.058941</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.619750</td>\n",
              "      <td>0.619945</td>\n",
              "      <td>0.623665</td>\n",
              "      <td>0.62112</td>\n",
              "      <td>0.001801</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>8.864776</td>\n",
              "      <td>0.158237</td>\n",
              "      <td>3.281153</td>\n",
              "      <td>0.379659</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.610511</td>\n",
              "      <td>0.616465</td>\n",
              "      <td>0.608184</td>\n",
              "      <td>0.61172</td>\n",
              "      <td>0.003487</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3.181335</td>\n",
              "      <td>0.139411</td>\n",
              "      <td>1.258011</td>\n",
              "      <td>0.029660</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.603072</td>\n",
              "      <td>0.603744</td>\n",
              "      <td>0.609144</td>\n",
              "      <td>0.60532</td>\n",
              "      <td>0.002718</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.085138</td>\n",
              "      <td>0.105993</td>\n",
              "      <td>1.595813</td>\n",
              "      <td>0.265521</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.598632</td>\n",
              "      <td>0.606504</td>\n",
              "      <td>0.598584</td>\n",
              "      <td>0.60124</td>\n",
              "      <td>0.003722</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>3.567600</td>\n",
              "      <td>0.325877</td>\n",
              "      <td>1.255680</td>\n",
              "      <td>0.011307</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.601752</td>\n",
              "      <td>0.598944</td>\n",
              "      <td>0.603024</td>\n",
              "      <td>0.60124</td>\n",
              "      <td>0.001705</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>3.412358</td>\n",
              "      <td>0.332227</td>\n",
              "      <td>1.351151</td>\n",
              "      <td>0.094656</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.599112</td>\n",
              "      <td>0.599064</td>\n",
              "      <td>0.601824</td>\n",
              "      <td>0.60000</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>9.305527</td>\n",
              "      <td>0.119190</td>\n",
              "      <td>2.827225</td>\n",
              "      <td>0.040946</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.596712</td>\n",
              "      <td>0.596304</td>\n",
              "      <td>0.598824</td>\n",
              "      <td>0.59728</td>\n",
              "      <td>0.001104</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>9.400665</td>\n",
              "      <td>0.126330</td>\n",
              "      <td>2.890951</td>\n",
              "      <td>0.049086</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>LexiconCountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.591193</td>\n",
              "      <td>0.595824</td>\n",
              "      <td>0.591984</td>\n",
              "      <td>0.59300</td>\n",
              "      <td>0.002023</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.971872</td>\n",
              "      <td>0.087745</td>\n",
              "      <td>1.272841</td>\n",
              "      <td>0.019742</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.589753</td>\n",
              "      <td>0.582743</td>\n",
              "      <td>0.592824</td>\n",
              "      <td>0.58844</td>\n",
              "      <td>0.004219</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3.049830</td>\n",
              "      <td>0.037506</td>\n",
              "      <td>1.445390</td>\n",
              "      <td>0.288852</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.581234</td>\n",
              "      <td>0.589344</td>\n",
              "      <td>0.588984</td>\n",
              "      <td>0.58652</td>\n",
              "      <td>0.003741</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.041712</td>\n",
              "      <td>0.065442</td>\n",
              "      <td>1.623191</td>\n",
              "      <td>0.302372</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.586633</td>\n",
              "      <td>0.584903</td>\n",
              "      <td>0.587544</td>\n",
              "      <td>0.58636</td>\n",
              "      <td>0.001095</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>3.333887</td>\n",
              "      <td>0.372279</td>\n",
              "      <td>1.258518</td>\n",
              "      <td>0.021621</td>\n",
              "      <td>LogisticRegression(max_iter=1000)</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': LogisticRegression(max_iter=100...</td>\n",
              "      <td>0.579074</td>\n",
              "      <td>0.585263</td>\n",
              "      <td>0.586943</td>\n",
              "      <td>0.58376</td>\n",
              "      <td>0.003384</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.004072</td>\n",
              "      <td>0.034164</td>\n",
              "      <td>1.519010</td>\n",
              "      <td>0.324251</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>TfidfVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.576434</td>\n",
              "      <td>0.578063</td>\n",
              "      <td>0.580223</td>\n",
              "      <td>0.57824</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.060157</td>\n",
              "      <td>1.041363</td>\n",
              "      <td>1.451717</td>\n",
              "      <td>0.225458</td>\n",
              "      <td>MultinomialNB()</td>\n",
              "      <td>CountVectorizer()</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'classifier': MultinomialNB(), 'representatio...</td>\n",
              "      <td>0.574634</td>\n",
              "      <td>0.577463</td>\n",
              "      <td>0.572423</td>\n",
              "      <td>0.57484</td>\n",
              "      <td>0.002063</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-135cd3b5-4d58-43fb-9f12-cab144ffbe31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-135cd3b5-4d58-43fb-9f12-cab144ffbe31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-135cd3b5-4d58-43fb-9f12-cab144ffbe31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1eac7f27-c795-4ad4-9eb7-56989b0e3d40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1eac7f27-c795-4ad4-9eb7-56989b0e3d40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1eac7f27-c795-4ad4-9eb7-56989b0e3d40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 54,\n  \"fields\": [\n    {\n      \"column\": \"mean_fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4554389349556045,\n        \"min\": 2.971872329711914,\n        \"max\": 15.212402105331421,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          9.682408571243286,\n          3.049829880396525,\n          2.971872329711914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3897539463875911,\n        \"min\": 0.03236053874175199,\n        \"max\": 2.707447287050294,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.2524823634735747,\n          0.03750593998458937,\n          0.08774461826036002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_score_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8396175910841482,\n        \"min\": 1.2555469671885173,\n        \"max\": 3.7623658974965415,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          3.2438973585764566,\n          1.4453895886739094,\n          1.2728411356608074\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_score_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14166730240706676,\n        \"min\": 0.01130695132615103,\n        \"max\": 0.682876462362577,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.28288590287872195,\n          0.2888521494245637,\n          0.019742067073741605\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"param_classifier\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"MultinomialNB()\",\n          \"LogisticRegression(max_iter=1000)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"param_representation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"TfidfVectorizer()\",\n          \"LexiconCountVectorizer()\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"param_representation__max_df\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08241633836921343,\n        \"min\": 0.8,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.9,\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"param_representation__min_df\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3716358534199435,\n        \"min\": 0.1,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split0_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10777343121669897,\n        \"min\": 0.5746340292776578,\n        \"max\": 0.8884089272858171,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          0.7950563954883609,\n          0.5986321094312455\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split1_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10751652409941417,\n        \"min\": 0.577463098523941,\n        \"max\": 0.8816752670106804,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.8065522620904836,\n          0.5893435737429498\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split2_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10880006328037907,\n        \"min\": 0.5724228969158767,\n        \"max\": 0.8882755310212409,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          0.7727109084363375,\n          0.5985839433577343\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10797599190589402,\n        \"min\": 0.5748400082391585,\n        \"max\": 0.8857998956387342,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.8009600873595778,\n          0.5865202114684059\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_test_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017690776421373487,\n        \"min\": 0.00027456677989863256,\n        \"max\": 0.007270944802340762,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          0.003985722646899102,\n          0.0037411567496285526\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank_test_score\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          20,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Mostramos los resultados de la búsqueda de hiperparámetros ordenados por el puntaje de validación cruzada promedio de mayor a menor\n",
        "df_results = pd.DataFrame(search.cv_results_)\n",
        "df_results.sort_values(by='mean_test_score', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj4NdvVoDosS"
      },
      "source": [
        "En la tabla anterior se evidencia que en general los modelos de Regresión Logística obtienen un mejor desemepeño que los modelos de Naive Bayes. También se observa que en general las mejores representaciones de texto son `TfidfVectorizer`, `LexiconCountVectorizer`, `CountVectorizer`, y `LexiconVectorizer` en el orden correspondiente, y finalmente se observa que para los vectorizadores los mejores hiperpárametros son utilizar todas las palabras presentes en el corpus a excepción de aquellas con una única ocurrencia.\n",
        "\n",
        "# 4. Evaluación de los clasificadores\n",
        "\n",
        "Finalmente, hacemos uso del set de evaluación para validar el desempeño de nuestro modelo.\n",
        "\n",
        "En primer lugar, cargamos el set de evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "3Z6ECihbDosS",
        "outputId": "2ce0e386-b619-4f3a-97ce-1292cd0b3c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primeras 5 filas del conjunto de datos de prueba de reseñas de IMDB en en español:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  When I was a kid, I loved \"Tiny Toons\". I espe...          1\n",
              "1  The setup for \"Nature of the Beast\" is ingenio...          0\n",
              "2  I do not have much to say than this is a great...          1\n",
              "3  Extremely formulaic with cosmic-sized logic ho...          0\n",
              "4  I actually liked certain things about this gam...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac0033b0-afae-440f-83c2-f55965fbea88\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When I was a kid, I loved \"Tiny Toons\". I espe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The setup for \"Nature of the Beast\" is ingenio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I do not have much to say than this is a great...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Extremely formulaic with cosmic-sized logic ho...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I actually liked certain things about this gam...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac0033b0-afae-440f-83c2-f55965fbea88')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac0033b0-afae-440f-83c2-f55965fbea88 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac0033b0-afae-440f-83c2-f55965fbea88');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32ca4ae2-ff4a-4af1-a019-4b590278377a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32ca4ae2-ff4a-4af1-a019-4b590278377a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32ca4ae2-ff4a-4af1-a019-4b590278377a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 25000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24801,\n        \"samples\": [\n          \"This is a classic continuation to Bleu, the likewise excellent film, with Juliet Binouche as a main star, moreover, she is a cameo appearance here, in Rouge, just for a second at the very end. But this film, truly red and very sweet although very sad, is a real winner. The main heroine, played by ever great Irene Jakob, is a successful photo / fashion model. She leads a full, active life, only darkened by her traumatic relations with her weird friend Mike, who is in England. By some lucky chance, she gets friendly with the old Judge, who spends time listening to the private telephone talks of his neighbors. The story starts to weave even further, and we see him in court, being almost universally condemned for his pastime. She is the only one who feels sympathy for him, for his cute doggy Rita and her pups, and for all the people who surround them. We also witness the break-up of a happy couple of a young lawyer and his lady, and their quarrel is also fueled by that telephone scandal... But the film is not about this, even. It is mostly about the loneliness and deep rifts between people, far and near. When she sails to England on a ferry, with that lawyer as a chance fellow-passenger, as well as that earlier mentioned Binoche who starred in Bleu, the ship sinks and we see the horrified look of The Judge when he watches the news trying to guess if she survived. She did, and still we feel very heavy at heart. Mr. Kislowski managed to draw a grand, subtle story about the solitude, misunderstanding, secrets and pain. Deep, dark personal pain of those who are lost and lonely. Brilliant film.\",\n          \"AWFUL wot more can i say i remember seeing it in the cinema (see how it sticks painfully in the memory)as a 16 yr old lad. Mark Hamill was the older generations skywalker and wasn't great at that, he was worse in this. Plus a dour soundtrack by Then Jericho AAAAARRRRRRGGGGGGHHHHHH. There is one film equally as bad as this i saw in the cinema Arthur 2 on the rocks. Funny how that question \\\"What is the worst film you have ever seen is?\\\" is easier than \\\"what is the best film?\\\" which incidentally varies between The Italian Job (original), Untouchables, Casino, Things to Do in Denver, Goodfellas (getting a sense of what I like??? - this will fool you!) Finding Nemo, Pirates of The Caribbean and Moulin Rouge! Please Never Watch this film or it will stick in your memory too!\",\n          \"OK, it's a piece of historical film making that caused an uproar, shocked people, and was banned. I'll give it that, which is why I gave it a 3 rather than a 1. It may have been ahead of the times, but it's certainly way behind the times now. I am a BIG fan of Salvador Dali and I loved Un Chien Andalou. That short was captivating with one creative scene after another. L'age d'Or was way too long and dull - just a self-indulgent piece of pompous film making created simply as a feeble attempt to try to out-do Un Chien Andalou by creating a full- length movie (and shamelessly leverage Dali's name and fame even though he had little to do with it). Total junk except for a (very) few shots of \\\"shocking scenes\\\" separated by long stretches of boring non-action. A waste of time and money. Both of my thumbs are down, way down. It'll go onto my shelf never to be watched again.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "df_test = load_imdb_reviews('./data/imdb_reviews_test.csv')\n",
        "print(\"\\nPrimeras 5 filas del conjunto de datos de prueba de reseñas de IMDB en en español:\")\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVQ64HlBDosS"
      },
      "source": [
        "Ahora calculamos el accuracy del modelo con mejor desempeño:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrwaNcglDosT",
        "outputId": "bfb4af76-5df7-4752-ce7b-e29d6c073284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8854"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "search.best_estimator_.score(df_test[\"review\"], df_test[\"sentiment\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QILyvYEODosT"
      },
      "source": [
        "También podemos ver la matriz de confusión generada por nuestro modelo en el set evaluación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "eCHMf94aDosT",
        "outputId": "0d597bd0-8bf1-4ded-9206-a276978c3949"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Realizamos la predicción sobre el conjunto de prueba\n",
        "y_pred = search.best_estimator_.predict(df_test[\"review\"])\n",
        "\n",
        "# Construimos la matriz de confusión\n",
        "conf_mtx = confusion_matrix(df_test[\"sentiment\"], y_pred, normalize='true')\n",
        "\n",
        "# Mostramos la matriz de confusión\n",
        "disp = ConfusionMatrixDisplay(conf_mtx, display_labels=[\"neg\",\"pos\"])\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBMaGQyRDosT"
      },
      "source": [
        "Otras métricas que pueder ser relevantes según el problema son el `f1-score`, la precisión, y la sensitividad, ya sean macro o micro:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua_GaJIJDosT",
        "outputId": "b944f7fd-e3c8-4291-ff6f-24bd6fb3cf06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.88      0.89      0.89     12500\n",
            "         pos       0.89      0.88      0.89     12500\n",
            "\n",
            "    accuracy                           0.89     25000\n",
            "   macro avg       0.89      0.89      0.89     25000\n",
            "weighted avg       0.89      0.89      0.89     25000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(df_test[\"sentiment\"], y_pred, target_names=[\"neg\", \"pos\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYBFwm7BDosT"
      },
      "source": [
        "Veamos ejemplos de clasificación de nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idamqvZJDosT",
        "outputId": "4be6b964-8e24-45c9-9850-00477d5d575b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo positivo: 1\n",
            "Ejemplo negativo: 0\n"
          ]
        }
      ],
      "source": [
        "pos_example = \"I loved this movie, it was amazing!\"\n",
        "neg_example = \"I hated this movie, it was terrible!\"\n",
        "\n",
        "print(f'Ejemplo positivo: {search.best_estimator_.predict([pos_example])[0]}')\n",
        "print(f'Ejemplo negativo: {search.best_estimator_.predict([neg_example])[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KJrr3pKiDosT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}